{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09f7f35-ead4-4062-ba9d-eda33f8f6626",
   "metadata": {},
   "source": [
    "# Classifier Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b30940-0098-497c-a25f-7d2c69a151ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "    \n",
    "import pickle as pickle\n",
    "from src.Utils import DataUtil\n",
    "from src.Trainer import CaseDataSet\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db41965-26d5-4eca-974a-a66c6bc5e101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(log, train=0.64, val=0.16):\n",
    "    data_size = log.shape[0]\n",
    "    training_set = log[:int(train * data_size)]\n",
    "    validation_set = log[int(train * data_size): int(train * data_size) + int(val * data_size)]\n",
    "    test_set = log[int(train * data_size) + int(val * data_size): ]\n",
    "    return training_set, validation_set, test_set\n",
    "\n",
    "\n",
    "def norm_remtime(train, val, test, columns=[\"RemTime\", \"LapseTime\"]):\n",
    "    for column in columns:\n",
    "        max_value = train[column].explode(column).max()\n",
    "        train.loc[:, column] = train[column] / max_value\n",
    "        val.loc[:, column] = val[column] / max_value\n",
    "        test.loc[:, column] = test[column] / max_value \n",
    "    return train, val, test\n",
    "\n",
    "with open(\"../../presets/t2.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "d1 = data[\"traces_dict\"][\"bpmn1-log_trace\"]\n",
    "train, val, test = split_data(d1)\n",
    "train, val, test = norm_remtime(train, val, test)\n",
    "train_t1 = CaseDataSet.CaseDataset(train, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"Next_flowNodeId\", encoding=\"Last\")\n",
    "val_t1 = CaseDataSet.CaseDataset(val, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"Next_flowNodeId\", encoding=\"Last\")\n",
    "test_t1 = CaseDataSet.CaseDataset(test, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"Next_flowNodeId\", encoding=\"Last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7091de5f-4dbc-483d-906d-52ecc6d184f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class XgbClassifier():\n",
    "    def __init__(self, training_set, validation_set, tree_method=\"hist\", early_stopping_rounds=2):\n",
    "        self.training_set = training_set\n",
    "        self.validation_set = validation_set\n",
    "        self.dataset_list = [self.training_set, self.validation_set]\n",
    "        self.data_list = []\n",
    "        self.le = preprocessing.LabelEncoder()\n",
    "        self.train_input = self.generate_data_set(self.training_set, training_set=True)\n",
    "        self.val_input = self.generate_data_set(self.validation_set)\n",
    "        self.clf = xgb.XGBClassifier(objective='multi:softprob', tree_method=tree_method,\n",
    "                                    early_stopping_rounds=early_stopping_rounds, num_class=self.le.classes_.shape[0])\n",
    "        self.eval_result = {}\n",
    "\n",
    "    def generate_data_set(self, dataset, training_set=False):\n",
    "        feature_list = []\n",
    "        label_list = []\n",
    "        for prefix_len in range(1, dataset.max_case_len+1):\n",
    "            dataset.set_prefix_length(prefix_len)\n",
    "            if dataset:\n",
    "                feature_list.append(dataset[:][0].numpy())\n",
    "                label_list.append(dataset[:][1].numpy())\n",
    "            else:\n",
    "                break\n",
    "        output = [np.vstack(feature_list), np.argmax(np.vstack(label_list), axis=-1)]\n",
    "        if training_set:\n",
    "            self.le.fit(output[1].ravel())\n",
    "            \n",
    "        return [output[0], self.le.transform(output[1].ravel())]\n",
    "\n",
    "    def train(self):\n",
    "        self.clf.fit(self.train_input[0], self.train_input[1],\n",
    "                     eval_set=[(self.val_input[0], self.val_input[1])], verbose=False)\n",
    "\n",
    "    def score(self):\n",
    "        return self.clf.score(self.val_input[0], self.val_input[1])\n",
    "    \n",
    "    def predict(self, test_set):\n",
    "        test_input = self.generate_data_set(test_set)\n",
    "        return self.clf.predict(test_input[0]), test_input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56785355-0d45-4b90-b07b-5c7f817fffb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c1 = XgbClassifier(train_t1, val_t1, tree_method=\"hist\", early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38e41c40-2745-48be-a523-c1cdf942615a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fe3337d-8a23-4834-83df-0f1dd513b323",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9869080781936646,\n",
       " 0.6740124821662903,\n",
       " 0.4785560369491577,\n",
       " 0.34587395191192627,\n",
       " 0.2524484097957611,\n",
       " 0.18539001047611237,\n",
       " 0.13672105967998505,\n",
       " 0.1011570617556572,\n",
       " 0.07505466789007187,\n",
       " 0.05584023147821426,\n",
       " 0.04166677221655846,\n",
       " 0.03119615092873573,\n",
       " 0.02345160767436028,\n",
       " 0.01771728508174419,\n",
       " 0.01346680615097284,\n",
       " 0.01031165756285191,\n",
       " 0.00796549580991268,\n",
       " 0.00621637655422091,\n",
       " 0.00490759033709764,\n",
       " 0.00392359308898449,\n",
       " 0.003179234219715,\n",
       " 0.00261170673184097,\n",
       " 0.00217489316128194,\n",
       " 0.00183542026206851,\n",
       " 0.00156865303870291,\n",
       " 0.00156865303870291,\n",
       " 0.00156865303870291,\n",
       " 0.00156865303870291,\n",
       " 0.00156865303870291,\n",
       " 0.00156865303870291]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.clf.evals_result_['validation_0']['mlogloss']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
