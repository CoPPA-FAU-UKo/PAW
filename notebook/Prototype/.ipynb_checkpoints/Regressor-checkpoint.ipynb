{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "481d70e9-3701-471e-8d44-465e59647a38",
   "metadata": {},
   "source": [
    "# Regressor Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55c6e7c5-a919-4951-b8da-690bd710f28d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import pickle as pickle\n",
    "from src.Utils import DataUtil\n",
    "from src.Trainer import CaseDataSet\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d65931cd-ca71-4ca2-9e8c-0101a75781e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(log, train=0.64, val=0.16):\n",
    "    data_size = log.shape[0]\n",
    "    training_set = log[:int(train * data_size)]\n",
    "    validation_set = log[int(train * data_size): int(train * data_size) + int(val * data_size)]\n",
    "    test_set = log[int(train * data_size) + int(val * data_size): ]\n",
    "    return training_set, validation_set, test_set\n",
    "\n",
    "\n",
    "def norm_remtime(train, val, test, columns=[\"RemTime\", \"LapseTime\"]):\n",
    "    for column in columns:\n",
    "        max_value = train[column].explode(column).max()\n",
    "        train.loc[:, column] = train[column] / max_value\n",
    "        val.loc[:, column] = val[column] / max_value\n",
    "        test.loc[:, column] = test[column] / max_value \n",
    "    return train, val, test\n",
    "\n",
    "with open(\"../../presets/t2.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "d1 = data[\"traces_dict\"][\"bpmn1-log_trace\"]\n",
    "train, val, test = split_data(d1)\n",
    "train, val, test = norm_remtime(train, val, test)\n",
    "train_t1 = CaseDataSet.CaseDataset(train, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"RemTime\", encoding=\"Last\")\n",
    "val_t1 = CaseDataSet.CaseDataset(val, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"RemTime\", encoding=\"Last\")\n",
    "test_t1 = CaseDataSet.CaseDataset(test, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"RemTime\", encoding=\"Last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "832d0497-d36e-4cd3-8a89-e582a06b1790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class XgbRegressor():\n",
    "    def __init__(self, training_set, validation_set, tree_method=\"hist\", early_stopping_rounds=2):\n",
    "        self.training_set = training_set\n",
    "        self.validation_set = validation_set\n",
    "        self.dataset_list = [self.training_set, self.validation_set]\n",
    "        self.data_list = []\n",
    "        self.reg = xgb.XGBRegressor(objective=\"reg:absoluteerror\", tree_method=tree_method,\n",
    "                                    early_stopping_rounds=early_stopping_rounds)\n",
    "        self.train_input = self.generate_data_set(self.training_set)\n",
    "        self.val_input = self.generate_data_set(self.validation_set)\n",
    "        self.eval_result = {}\n",
    "\n",
    "    def generate_data_set(self, dataset):\n",
    "        feature_list = []\n",
    "        label_list = []\n",
    "        for prefix_len in range(1, dataset.max_case_len+1):\n",
    "            dataset.set_prefix_length(prefix_len)\n",
    "            feature_list.append(dataset[:][0].numpy())\n",
    "            label_list.append(dataset[:][1].numpy())\n",
    "        return [np.vstack(feature_list), np.vstack(label_list)]\n",
    "\n",
    "    def train(self):\n",
    "        self.reg.fit(self.train_input[0], self.train_input[1],\n",
    "                     eval_set=[(self.val_input[0], self.val_input[1])], verbose=False)\n",
    "\n",
    "    def score(self):\n",
    "        return self.reg.score(self.val_input[0], self.val_input[1])\n",
    "    \n",
    "    def predict(self, test_set):\n",
    "        test_input = self.generate_data_set(test_set)\n",
    "        return self.reg.predict(test_input[0]), test_input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8eb380ca-c1c6-4436-8f30-e966244c9755",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r1 = XgbRegressor(train_t1, val_t1, tree_method=\"hist\", early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a449e989-3846-4f51-bfc1-840e4f923c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a3bde7fb-097c-469d-a344-63252bda90b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.1165352e-01, 2.1165352e-01, 2.1165352e-01, ..., 2.5715224e-05,\n",
       "        2.5715224e-05, 2.5715224e-05], dtype=float32),\n",
       " array([[0.24752475],\n",
       "        [0.26308345],\n",
       "        [0.24045262],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.predict(test_t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
