{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e2020b-4a50-4e05-a264-3074494b362c",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85dc9757-0890-4e01-a4be-f9ba7f0d2022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "from torch.nn import functional as F\n",
    "from sklearn import preprocessing\n",
    "from joblib import dump, load\n",
    "import torch\n",
    "from torch import nn\n",
    "import importlib\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from src.Trainer import CaseDataSet\n",
    "from src.Model import DLModels\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from src.Trainer import Regressor\n",
    "from src.Trainer import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231a541f-286d-4dbe-b856-afa6ce3175be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(log, train=0.64, val=0.16):\n",
    "    data_size = log.shape[0]\n",
    "    training_set = log[:int(train * data_size)]\n",
    "    validation_set = log[int(train * data_size): int(train * data_size) + int(val * data_size)]\n",
    "    test_set = log[int(train * data_size) + int(val * data_size): ]\n",
    "    return training_set, validation_set, test_set\n",
    "\n",
    "\n",
    "def norm_remtime(train, val, test, columns=[\"RemTime\", \"LapseTime\"]):\n",
    "    for column in columns:\n",
    "        max_value = train[column].explode(column).max()\n",
    "        train.loc[:, column] = train[column] / max_value\n",
    "        val.loc[:, column] = val[column] / max_value\n",
    "        test.loc[:, column] = test[column] / max_value \n",
    "    return train, val, test\n",
    "\n",
    "with open(\"../../presets/cs1.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "d1 = data[\"traces_dict\"][\"BPMN_cfc5_0_trace\"]\n",
    "train, val, test = split_data(d1)\n",
    "train, val, test = norm_remtime(train, val, test)\n",
    "train_t1 = CaseDataSet.CaseDataset(train, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"RemTime\", encoding=\"all\")\n",
    "val_t1 = CaseDataSet.CaseDataset(val, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"RemTime\", encoding=\"all\")\n",
    "test_t1 = CaseDataSet.CaseDataset(test, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"RemTime\", encoding=\"all\")\n",
    "\n",
    "train_t2 = CaseDataSet.CaseDataset(train, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"Next_flowNodeId\", encoding=\"all\")\n",
    "val_t2 = CaseDataSet.CaseDataset(val, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"Next_flowNodeId\", encoding=\"all\")\n",
    "test_t2 = CaseDataSet.CaseDataset(test, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"Next_flowNodeId\", encoding=\"all\")\n",
    "\n",
    "train_t3 = CaseDataSet.CaseDataset(train, feature_list=[\"LapseTime\"], label=\"RemTime\", encoding=\"all\")\n",
    "val_t3 = CaseDataSet.CaseDataset(val, feature_list=[\"LapseTime\"], label=\"RemTime\", encoding=\"all\")\n",
    "test_t3 = CaseDataSet.CaseDataset(test, feature_list=[\"LapseTime\"], label=\"RemTime\", encoding=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18734f04-9196-4a38-8758-c86be2e42b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12450831 0.11135403 0.10062728 0.08927501 0.08432638 0.08398965\n",
      " 0.07227605 0.07219254 0.0678773  0.07050477 0.06774218 0.06912424\n",
      " 0.06965837 0.06776809 0.07040636 0.06695155 0.06758011 0.06733677\n",
      " 0.06712783 0.06773037 0.06761889 0.06664499 0.06643182 0.06718372\n",
      " 0.06689198 0.06652468 0.06646566 0.06660349 0.06723823 0.06724643\n",
      " 0.06651557 0.06638288 0.06638517 0.06643062]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[array([[0.209874],\n",
       "         [0.209874],\n",
       "         [0.209874],\n",
       "         [0.209874],\n",
       "         [0.209874],\n",
       "         [0.209874],\n",
       "         [0.209874],\n",
       "         [0.209874],\n",
       "         [0.209874],\n",
       "         [0.209874]], dtype=float32),\n",
       "  array([[0.24752475],\n",
       "         [0.26308346],\n",
       "         [0.24045262],\n",
       "         [0.27015558],\n",
       "         [0.14144272],\n",
       "         [0.24752475],\n",
       "         [0.13437058],\n",
       "         [0.14851485],\n",
       "         [0.281471  ],\n",
       "         [0.19943424]], dtype=float32)],\n",
       " [array([[0.1474337 ],\n",
       "         [0.14681104],\n",
       "         [0.14681104],\n",
       "         [0.14681104],\n",
       "         [0.1471217 ],\n",
       "         [0.14681104],\n",
       "         [0.1474337 ],\n",
       "         [0.14681104],\n",
       "         [0.14650175],\n",
       "         [0.14650175]], dtype=float32),\n",
       "  array([[0.23338048],\n",
       "         [0.23479491],\n",
       "         [0.21216407],\n",
       "         [0.24186705],\n",
       "         [0.12022631],\n",
       "         [0.21923621],\n",
       "         [0.12022631],\n",
       "         [0.12022631],\n",
       "         [0.24611032],\n",
       "         [0.16407356]], dtype=float32)],\n",
       " [array([[0.11858921],\n",
       "         [0.11714606],\n",
       "         [0.11741744],\n",
       "         [0.11714606],\n",
       "         [0.11813876],\n",
       "         [0.1168759 ],\n",
       "         [0.11858921],\n",
       "         [0.11769004],\n",
       "         [0.11254016],\n",
       "         [0.11563283]], dtype=float32),\n",
       "  array([[0.21923621],\n",
       "         [0.20650637],\n",
       "         [0.19094767],\n",
       "         [0.2135785 ],\n",
       "         [0.10608204],\n",
       "         [0.18387553],\n",
       "         [0.10608204],\n",
       "         [0.10608204],\n",
       "         [0.10466761],\n",
       "         [0.10749646]], dtype=float32)],\n",
       " [array([[0.08779788],\n",
       "         [0.08593248],\n",
       "         [0.08662169],\n",
       "         [0.08575095],\n",
       "         [0.08737135],\n",
       "         [0.08281855],\n",
       "         [0.08761132],\n",
       "         [0.08694647],\n",
       "         [0.08102517],\n",
       "         [0.08460037]], dtype=float32),\n",
       "  array([[0.20509194],\n",
       "         [0.17821783],\n",
       "         [0.1768034 ],\n",
       "         [0.17821783],\n",
       "         [0.09193777],\n",
       "         [0.04243281],\n",
       "         [0.08486563],\n",
       "         [0.09193777],\n",
       "         [0.09618105],\n",
       "         [0.09335219]], dtype=float32)],\n",
       " [array([[0.09668738],\n",
       "         [0.09436452],\n",
       "         [0.09538591],\n",
       "         [0.09405173],\n",
       "         [0.09623304],\n",
       "         [0.08909148],\n",
       "         [0.09636924],\n",
       "         [0.09578054],\n",
       "         [0.08870476],\n",
       "         [0.09299116]], dtype=float32),\n",
       "  array([[0.20509194],\n",
       "         [0.17821783],\n",
       "         [0.1768034 ],\n",
       "         [0.17821783],\n",
       "         [0.09193777],\n",
       "         [0.04243281],\n",
       "         [0.08486563],\n",
       "         [0.09193777],\n",
       "         [0.09618105],\n",
       "         [0.09335219]], dtype=float32)],\n",
       " [array([[0.07093363],\n",
       "         [0.06959388],\n",
       "         [0.0703368 ],\n",
       "         [0.06866251],\n",
       "         [0.07064838],\n",
       "         [0.06711216],\n",
       "         [0.07077688],\n",
       "         [0.07044262],\n",
       "         [0.06713779],\n",
       "         [0.06919371]], dtype=float32),\n",
       "  array([[0.19094767],\n",
       "         [0.14285715],\n",
       "         [0.16265912],\n",
       "         [0.07213578],\n",
       "         [0.07072136],\n",
       "         [0.03394625],\n",
       "         [0.07072136],\n",
       "         [0.07072136],\n",
       "         [0.08910891],\n",
       "         [0.07920792]], dtype=float32)],\n",
       " [array([[0.04496975],\n",
       "         [0.04469071],\n",
       "         [0.04486976],\n",
       "         [0.04457974],\n",
       "         [0.04494197],\n",
       "         [0.0441391 ],\n",
       "         [0.0449566 ],\n",
       "         [0.04490492],\n",
       "         [0.04411899],\n",
       "         [0.04465363]], dtype=float32),\n",
       "  array([[0.15558699],\n",
       "         [0.0367751 ],\n",
       "         [0.13437058],\n",
       "         [0.05799151],\n",
       "         [0.05657709],\n",
       "         [0.02687412],\n",
       "         [0.04950495],\n",
       "         [0.05657709],\n",
       "         [0.08203678],\n",
       "         [0.07072136]], dtype=float32)],\n",
       " [array([[0.02672108],\n",
       "         [0.0263211 ],\n",
       "         [0.02658017],\n",
       "         [0.02622054],\n",
       "         [0.02670236],\n",
       "         [0.02594934],\n",
       "         [0.02671874],\n",
       "         [0.02666205],\n",
       "         [0.02600748],\n",
       "         [0.02646586]], dtype=float32),\n",
       "  array([[0.12022631],\n",
       "         [0.02263083],\n",
       "         [0.02828854],\n",
       "         [0.04384724],\n",
       "         [0.04101839],\n",
       "         [0.01980198],\n",
       "         [0.03536068],\n",
       "         [0.02828854],\n",
       "         [0.07496464],\n",
       "         [0.06364922]], dtype=float32)],\n",
       " [array([[0.01327883],\n",
       "         [0.01269874],\n",
       "         [0.01307724],\n",
       "         [0.0127075 ],\n",
       "         [0.01345811],\n",
       "         [0.012561  ],\n",
       "         [0.01349495],\n",
       "         [0.01340462],\n",
       "         [0.01267476],\n",
       "         [0.01321175]], dtype=float32),\n",
       "  array([[0.01414427],\n",
       "         [0.00848656],\n",
       "         [0.01414427],\n",
       "         [0.03536068],\n",
       "         [0.01272984],\n",
       "         [0.01272984],\n",
       "         [0.02121641],\n",
       "         [0.01414427],\n",
       "         [0.06082037],\n",
       "         [0.05091938]], dtype=float32)],\n",
       " [array([[0.00196712],\n",
       "         [0.00182711],\n",
       "         [0.00187672],\n",
       "         [0.00185194],\n",
       "         [0.00161907],\n",
       "         [0.00174826],\n",
       "         [0.00158492],\n",
       "         [0.00163726],\n",
       "         [0.00187076],\n",
       "         [0.0017665 ]], dtype=float32),\n",
       "  array([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]], dtype=float32)]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.NAdam\n",
    "loss = nn.L1Loss()\n",
    "r1 = Regressor.LstmRegressor(train_t1, val_t1, 256, 2, optimizer, loss, 10, 40, 10)\n",
    "r1.train()\n",
    "print(r1.val_score)\n",
    "r1.predict(test_t1)\n",
    "r1.evaluation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2160497-1c08-4be2-b602-3b5502defd9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mL1Loss()\n\u001b[0;32m      3\u001b[0m r2 \u001b[38;5;241m=\u001b[39m Regressor\u001b[38;5;241m.\u001b[39mLstmRegressor(train_t3, val_t3, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m2\u001b[39m, optimizer, loss, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mr2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(r2\u001b[38;5;241m.\u001b[39mval_score)\n\u001b[0;32m      6\u001b[0m r2\u001b[38;5;241m.\u001b[39mpredict(test_t3)\n",
      "File \u001b[1;32mH:\\PhD\\CoPPA_Trainer\\src\\Trainer\\Regressor.py:203\u001b[0m, in \u001b[0;36mLstmRegressor.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_score, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m                                                               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_package\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_ob_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mH:\\PhD\\CoPPA_Trainer\\src\\Trainer\\Regressor.py:103\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, optimizer, criterion, training_set, test_set, batch_size, torch_device, device_package, max_epoch, max_ob_iter, score_margin, print_iter)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iter_epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_epoch):\n\u001b[0;32m    102\u001b[0m     device_package\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m--> 103\u001b[0m     loss_train, sample_num_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mtorch_device\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     device_package\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m    108\u001b[0m     loss_test, sample_num_test \u001b[38;5;241m=\u001b[39m train_model_epoch(model, test_set, batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    109\u001b[0m                                                    optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m    110\u001b[0m                                                    criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[0;32m    111\u001b[0m                                                    torch_device\u001b[38;5;241m=\u001b[39mtorch_device,\n\u001b[0;32m    112\u001b[0m                                                    training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mH:\\PhD\\CoPPA_Trainer\\src\\Trainer\\Regressor.py:70\u001b[0m, in \u001b[0;36mtrain_model_epoch\u001b[1;34m(model, training_set, optimizer, criterion, torch_device, batch_size, training)\u001b[0m\n\u001b[0;32m     68\u001b[0m x \u001b[38;5;241m=\u001b[39m input_data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;28mint\u001b[39m(batch_size \u001b[38;5;241m*\u001b[39m i): \u001b[38;5;28mint\u001b[39m(batch_size \u001b[38;5;241m*\u001b[39m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(torch_device)\n\u001b[0;32m     69\u001b[0m y \u001b[38;5;241m=\u001b[39m input_data[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;28mint\u001b[39m(batch_size \u001b[38;5;241m*\u001b[39m i): \u001b[38;5;28mint\u001b[39m(batch_size \u001b[38;5;241m*\u001b[39m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(torch_device)\n\u001b[1;32m---> 70\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n",
      "File \u001b[1;32m~\\.conda\\envs\\coppa\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\coppa\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mH:\\PhD\\CoPPA_Trainer\\src\\Model\\DLModels.py:19\u001b[0m, in \u001b[0;36mSimpleLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Forward propagate LSTM\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# out: tensor of shape (batch_size, seq_length, hidden_size)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m     22\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out)\n",
      "File \u001b[1;32m~\\.conda\\envs\\coppa\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\coppa\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\coppa\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:911\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    908\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 911\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    915\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.NAdam\n",
    "loss = nn.L1Loss()\n",
    "r2 = Regressor.LstmRegressor(train_t3, val_t3, 256, 2, optimizer, loss, 10, 40, 10)\n",
    "r2.train()\n",
    "print(r2.val_score)\n",
    "r2.predict(test_t3)\n",
    "r2.evaluation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "226ce0ea-b124-4486-8464-95d1a61b8250",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43692731, 0.18493647, 0.16269908, 0.15132849, 0.14558674,\n",
       "       0.18359129, 0.18846746, 0.15515916, 0.15858121, 0.16469393,\n",
       "       0.15647641, 0.14367554, 0.14895851, 0.15724686, 0.15263314,\n",
       "       0.14575758, 0.14443267, 0.14309181, 0.17925664, 0.15606715,\n",
       "       0.14401011, 0.16560391, 0.15992853, 0.1431518 , 0.14297299,\n",
       "       0.15214764, 0.14506433, 0.18105437, 0.14808999, 0.15533164,\n",
       "       0.1462348 , 0.1483689 , 0.16836962, 0.14643556, 0.15438226,\n",
       "       0.14644883])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.NAdam\n",
    "loss = nn.CrossEntropyLoss()\n",
    "num_class = train_t2[:][0].shape[-1]-1\n",
    "c1 = Classifier.LstmClassifier(train_t2, val_t2, 256, 2, num_class, optimizer, loss, 10, 40, 10)\n",
    "c1.train()\n",
    "c1.val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8824d42a-fb6d-47fc-b76e-935af00f10f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 10 and the array at index 6 has size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mc1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_t2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m c1\u001b[38;5;241m.\u001b[39mevaluation_list\n",
      "File \u001b[1;32mH:\\PhD\\CoPPA_Trainer\\src\\Trainer\\Classifier.py:216\u001b[0m, in \u001b[0;36mLstmClassifier.predict\u001b[1;34m(self, test_set)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, test_set):\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_list, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_num_list \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_package\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mH:\\PhD\\CoPPA_Trainer\\src\\Trainer\\Classifier.py:174\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, test_set, torch_device, device_package, batch_size)\u001b[0m\n\u001b[0;32m    170\u001b[0m         label_list\u001b[38;5;241m.\u001b[39mappend(y\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m    172\u001b[0m         device_package\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m--> 174\u001b[0m     evaluation_list\u001b[38;5;241m.\u001b[39mappend([\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_list\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    175\u001b[0m                             np\u001b[38;5;241m.\u001b[39mvstack(label_list)])\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m evaluation_list, np\u001b[38;5;241m.\u001b[39marray(sample_num_list)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\coppa\\lib\\site-packages\\numpy\\core\\shape_base.py:282\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    281\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 10 and the array at index 6 has size 2"
     ]
    }
   ],
   "source": [
    "c1.predict(test_t2)\n",
    "c1.evaluation_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4de0ab13-4e82-423a-922f-4be5cf418b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([7, 6, 8, 1, 2, 9, 5, 3, 0, 4], dtype=int64),\n",
       "       array([7, 6, 8, 1, 2, 9, 5, 3, 0, 4], dtype=int64),\n",
       "       array([7, 6, 8, 1, 2, 9, 5, 3, 0, 4], dtype=int64),\n",
       "       array([7, 6, 8, 1, 2, 9, 5, 3, 0, 4], dtype=int64),\n",
       "       array([7, 6, 8, 1, 2, 9, 5, 3, 0, 4], dtype=int64),\n",
       "       array([7, 6, 8, 1, 2, 9, 5, 3, 0, 4], dtype=int64),\n",
       "       array([7, 6, 8, 1, 2, 9, 5, 3, 0, 4], dtype=int64),\n",
       "       array([7, 6, 8, 1, 2, 9, 5, 3, 0, 4], dtype=int64),\n",
       "       array([7, 6, 8, 1, 2, 9, 5, 3, 0, 4], dtype=int64),\n",
       "       array([7, 6, 8, 1, 2, 9, 5, 3, 0, 4], dtype=int64)], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[:10][\"flowNodeId\"].apply(lambda x: np.argmax(x, axis=-1)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "382f4e4c-38d9-4e14-aef6-9143d98043b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if importlib.util.find_spec(\"torch.backends.mps\") is not None:\n",
    "    if torch.backends.mps.is_available():\n",
    "        torch_device = torch.device(\"mps\")\n",
    "        device_package = torch.mps\n",
    "if torch.cuda.is_available():\n",
    "    torch_device = torch.device(\"cuda\")\n",
    "    device_package = torch.cuda\n",
    "            \n",
    "def evaluate_model(model, test_set, torch_device, device_package, batch_size=100):\n",
    "    training_data_set = test_set\n",
    "    res_list = []\n",
    "    ref_list = []\n",
    "    model.flatten()\n",
    "    device_package.empty_cache()\n",
    "    for prefix_len in range(1, test_set.max_case_len+1):\n",
    "        training_data_set.set_prefix_length(prefix_len)\n",
    "        input_data = training_data_set[:]\n",
    "        if input_data is None:\n",
    "            # print(\"Max length reached, abort\")\n",
    "            break\n",
    "        sample_num = input_data[0].shape[0]\n",
    "\n",
    "        output_list = []\n",
    "        label_list = []\n",
    "        batch_num = int(sample_num / batch_size)\n",
    "        for i in range(batch_num):\n",
    "            x = input_data[0][int(batch_size * i): int(batch_size * (i+1))].float().to(torch_device)\n",
    "            y = input_data[1][int(batch_size * i): int(batch_size * (i+1))].float().argmax(dim=-1)\n",
    "            outputs = model(x).detach().argmax(dim=-1)\n",
    "            output_list.append(outputs.cpu().numpy())\n",
    "            label_list.append(y.cpu().numpy().T)\n",
    "\n",
    "            device_package.empty_cache()\n",
    "\n",
    "        if sample_num > batch_size * batch_num:\n",
    "            x = input_data[0][batch_size * batch_num:].float().to(torch_device)\n",
    "            y = input_data[1][batch_size * batch_num:].float().argmax(dim=-1)\n",
    "            outputs = model(x).detach().argmax(dim=-1)\n",
    "            output_list.append(outputs.cpu().numpy())\n",
    "            label_list.append(y.cpu().numpy().T)\n",
    "\n",
    "            device_package.empty_cache()\n",
    "\n",
    "        res_list.append(np.hstack(output_list))\n",
    "        ref_list.append(np.hstack(label_list))\n",
    "\n",
    "    return np.hstack(res_list), np.hstack(ref_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "688e7ce9-da99-4a45-bd97-0ec6c33bde77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res, ref = evaluate_model(c1.model, test_t2, torch_device, device_package, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a7251136-9605-45ea-be39-1dd467950c25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "       9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37d1a9a8-9b15-469f-803d-0b52cabf4284",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 9, 3, 9, 3, 9, 3, 5, 3, 9, 5, 9, 9, 9, 9, 9, 9, 5, 3, 9, 5,\n",
       "        9, 9, 9, 5, 9, 9, 9, 9, 9, 9, 5, 5, 9, 9, 9, 9, 3, 3, 5, 3, 9, 9,\n",
       "        3, 3, 9, 5, 3, 9, 5, 9, 5, 9, 9, 5, 9, 5, 9, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
