{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "530256f8-17b0-40bb-9363-e71aac435757",
   "metadata": {},
   "source": [
    "# Feature Embedding Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4370f21-611a-4390-8da8-17f5e30e9626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47d63863-3ce4-422f-97ef-ee7737ebdaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, oov_rule=\"dummy\", dist=None):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.oov_rule = oov_rule # 'zero', 'mean', 'random', 'dummy', \"dist\"\n",
    "        self.dist = dist\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.oov_rule == 'dummy':\n",
    "            try:\n",
    "                y = self.embedding(x)\n",
    "            except:\n",
    "                print('ERROR: Expect dummy input to be considered already for embedding_dim (Add +1 to number of embeddings)')\n",
    "                raise\n",
    "        else:\n",
    "            where = torch.where(x >= self.num_embeddings)\n",
    "            x[where] = torch.tensor(0, dtype=x.dtype)\n",
    "            y = self.embedding(x)\n",
    "\n",
    "            if self.oov_rule == 'zero':\n",
    "                y[where] = torch.tensor(0., dtype=y.dtype)\n",
    "            elif self.oov_rule == 'mean':\n",
    "                mean = torch.mean(self.embedding.weight, axis=-2)\n",
    "                y[where] = torch.tensor(mean, dtype=y.dtype)\n",
    "            elif self.oov_rule == 'random':\n",
    "                values = torch.normal(mean=0., std=1., size=(y.shape))\n",
    "                y[where] = torch.tensor(values[where], dtype=y.dtype)\n",
    "            elif self.oov_rule == 'dist':\n",
    "                y[where] = torch.tensor(self.dist, dtype=y.dtype)\n",
    "            else:\n",
    "                raise ValueError('Invalid oov_rule')\n",
    "        return y\n",
    "\n",
    "\n",
    "class OneHotEmbedding(nn.Module):\n",
    "    def __init__(self, num_classes, rule=\"zero\", dist=None):\n",
    "        super(OneHotEmbedding, self).__init__()\n",
    "        self.rule = rule  # 'zero', 'one_over_n', 'random', 'dummy'\n",
    "        self.num_classes = num_classes\n",
    "        self.dist = dist\n",
    "\n",
    "    def forward(self, x):\n",
    "        where = torch.where(x >= self.num_classes)\n",
    "        x[where] = torch.tensor(0, dtype=x.dtype)\n",
    "        one_hot = torch.nn.functional.one_hot(x, num_classes=self.num_classes).float()\n",
    "\n",
    "        if self.rule == 'dummy':\n",
    "            one_hot = torch.nn.functional.one_hot(x, num_classes=self.num_classes+1).float()\n",
    "            dummy_class = torch.zeros(self.num_classes+1)\n",
    "            dummy_class[-1] = 1\n",
    "            one_hot[where] = dummy_class\n",
    "        elif self.rule == 'zero':\n",
    "            one_hot[where] = torch.tensor(0., dtype=one_hot.dtype)\n",
    "        elif self.rule == 'one_over_n':\n",
    "            one_hot[where] = torch.tensor(1/self.num_classes, dtype=one_hot.dtype)\n",
    "        elif self.rule == 'random':\n",
    "            one_hot[where] = torch.rand(size=one_hot.shape)[where].clone().detach().type(one_hot.dtype)\n",
    "        elif self.rule == 'dist':\n",
    "            one_hot[where] = torch.tensor(self.dist, dtype=one_hot.dtype)\n",
    "        else:\n",
    "            raise ValueError('Invalid rule')\n",
    "        return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc1b071d-36fe-44ee-92e3-58e1b7ef41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_t1 = Embedding(5,6)\n",
    "onehot_t1 = OneHotEmbedding(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da23aa5c-fe5b-463c-8d3e-6813e8ad243c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.tensor([8])\n",
    "onehot_t1.forward(t2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
