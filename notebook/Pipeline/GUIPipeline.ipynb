{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3025ad8b-542c-49a5-907c-c178391e39d9",
   "metadata": {},
   "source": [
    "# Backend pipeline for GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dea787c-863e-449d-920e-4f48c56cbde7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import pickle as pickle\n",
    "from src.Log import Reformat\n",
    "from src.Utils import DataUtil\n",
    "from src.Trainer import CaseDataSet\n",
    "from src.Trainer import Regressor\n",
    "from src.Trainer import Classifier\n",
    "from src.Preprocessing import Extraction\n",
    "from src.Preprocessing import Preprocess\n",
    "\n",
    "from src.Backend import DataProcessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "869b3429-4fbe-423c-b67b-3481b6a412c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logs = DataUtil.read_files(\"../../data/SimulatedLogs\", \".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb981e60-df5e-459d-bccd-883982739073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_pd = {}\n",
    "for file_name, data in logs.items():\n",
    "    log_pd[file_name] = DataProcessing.generate_trace(data, time_column=\"endDate\", case_column=\"processInstanceKey\", selected_columns=[\"flowNodeId\", \"endDate\", \"processInstanceKey\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dda3140f-b63f-495b-b7a2-8c2b2c2163dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t1 = log_pd['bpmn1-log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4db9063-e32c-4439-adff-3a0686575978",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../../presets/t2.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "811a6365-1e9b-4962-8a35-6e51d250c123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1 = data[\"traces_dict\"][\"bpmn1-log_trace\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207e2cb7-751f-44eb-8da8-29d16afb706e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t1 = CaseDataSet.CaseDataset(d1, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"RemTime\", encoding=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af96734-0c11-4efa-961f-46e0b5c8bb24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(log, train=0.64, val=0.16):\n",
    "    data_size = log.shape[0]\n",
    "    training_set = log[:int(train * data_size)]\n",
    "    validation_set = log[int(train * data_size): int(train * data_size) + int(val * data_size)]\n",
    "    test_set = log[int(train * data_size) + int(val * data_size): ]\n",
    "    return training_set, validation_set, test_set\n",
    "\n",
    "\n",
    "def norm_remtime(train, val, test, columns=[\"RemTime\", \"LapseTime\"]):\n",
    "    for column in columns:\n",
    "        max_value = train[column].explode(column).max()\n",
    "        train.loc[:, column] = train[column] / max_value\n",
    "        val.loc[:, column] = val[column] / max_value\n",
    "        test.loc[:, column] = test[column] / max_value \n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f88a4c1e-2f8f-42e5-8faf-75f69e5f583c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, val, test = split_data(d1)\n",
    "train, val, test = norm_remtime(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "746a5afc-f9ad-44c0-a389-0109796cd21e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_t1 = CaseDataSet.CaseDataset(train, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"RemTime\", encoding=\"all\")\n",
    "val_t1 = CaseDataSet.CaseDataset(val, feature_list=[\"flowNodeId\", \"LapseTime\"], label=\"RemTime\", encoding=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75fbdab3-5ca1-4adf-bcbb-5c6bd75b7e87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m r1 \u001b[38;5;241m=\u001b[39m \u001b[43mRegressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_t1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_t1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../../models/XGB/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/CoPPA_Trainer/src/Trainer/Regressor.py:17\u001b[0m, in \u001b[0;36mXGBTrainer.__init__\u001b[0;34m(self, training_set, validation_set, model_path, tree_method, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(tree_method\u001b[38;5;241m=\u001b[39mtree_method, early_stopping_rounds\u001b[38;5;241m=\u001b[39mearly_stopping_rounds)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_data_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/CoPPA_Trainer/src/Trainer/Regressor.py:28\u001b[0m, in \u001b[0;36mXGBTrainer.generate_data_set\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m     feature_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_list[i][:][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     26\u001b[0m     label_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_list[i][:][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list\u001b[38;5;241m.\u001b[39mappend([\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_list\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39mvstack(label_list)])\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/coppa/lib/python3.8/site-packages/numpy/core/shape_base.py:296\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    295\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 2"
     ]
    }
   ],
   "source": [
    "r1 = Regressor.XGBTrainer(train_t1, val_t1, \"../../models/XGB/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
